import openai
from openai import OpenAI
import pandas as pd
from datetime import datetime
import json
import re
import os

class GPTAnalyzer:
    """GPTë¥¼ ì´ìš©í•œ ì±„íŒ… ë¶„ì„ í´ë˜ìŠ¤"""
    
    def __init__(self, api_key):
        """OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
        self.model = "gpt-4o-mini"
        
        # API í‚¤ ê²€ì¦
        if not api_key or not api_key.startswith('sk-'):
            raise Exception("ìœ íš¨í•˜ì§€ ì•Šì€ OpenAI API í‚¤ì…ë‹ˆë‹¤.")
        
        try:
            # OpenAI 1.0+ ë²„ì „ ë°©ì‹ìœ¼ë¡œ í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
            self.client = OpenAI(api_key=api_key)
            
            print(f"âœ… OpenAI API í‚¤ ì„¤ì • ì™„ë£Œ (ëª¨ë¸: {self.model})")
            
        except Exception as e:
            print(f"âŒ OpenAI API í‚¤ ì„¤ì • ì‹¤íŒ¨: {str(e)}")
            raise Exception(f"OpenAI API ì„¤ì • ì‹¤íŒ¨. ì›ì¸: {str(e)}")
    
    def analyze_chat(self, data, analysis_type, target_user="ì „ì²´", detailed=False, include_context=True):
        """ì±„íŒ… ë°ì´í„°ë¥¼ ë¶„ì„"""
        
        # ë°ì´í„° ì „ì²˜ë¦¬
        if target_user != "ì „ì²´":
            data = data[data['user'] == target_user]
        
        # ë©”ì‹œì§€ê°€ ë„ˆë¬´ ë§ìœ¼ë©´ ìµœê·¼ ë©”ì‹œì§€ë¡œ ì œí•œ
        limit = 800 if detailed else 500
        if len(data) > limit:
            data = data.tail(limit)
        
        # ë¶„ì„ íƒ€ì…ë³„ í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = self.generate_prompt(data, analysis_type, target_user, include_context, detailed)
        
        try:
            max_tokens = 3000 if detailed else 2000
            
            # OpenAI 1.0+ ë²„ì „ API í˜¸ì¶œ ë°©ì‹
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ì¹´ì¹´ì˜¤í†¡ ì±„íŒ… ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ì±„íŒ… ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ìœ ìš©í•œ ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”. í•œêµ­ì–´ë¡œ ìì„¸í•˜ê³  êµ¬ì²´ì ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=max_tokens,
                temperature=0.7
            )
            
            analysis_result = response.choices[0].message.content
            
            # ê²°ê³¼ êµ¬ì¡°í™” (í–¥ìƒëœ ë²„ì „ ì‚¬ìš©)
            return self.structure_advanced_results(analysis_result, f"{analysis_type} ë¶„ì„", data)
            
        except Exception as e:
            return {
                "summary": f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
                "error": True,
                "analysis_type": analysis_type
            }
    
    def generate_prompt(self, data, analysis_type, target_user, include_context=True, detailed=False):
        """ë¶„ì„ íƒ€ì…ì— ë”°ë¥¸ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        
        # ë°ì´í„° ìš”ì•½
        if include_context:
            messages_text = "\n".join([
                f"[{row['datetime'].strftime('%Y-%m-%d %H:%M')}] {row['user']}: {row['message']}"
                for _, row in data.iterrows()
            ])
        else:
            messages_text = "\n".join([
                f"{row['user']}: {row['message']}"
                for _, row in data.iterrows()
            ])
        
        # í† í° ì œí•œ ì¡°ì •
        max_chars = 6000 if detailed else 4000
        if len(messages_text) > max_chars:
            messages_text = messages_text[:max_chars] + "\n... (ë” ë§ì€ ë©”ì‹œì§€ê°€ ìˆìŠµë‹ˆë‹¤)"
        
        # ì‚¬ìš©ìë³„ í†µê³„
        user_stats = data['user'].value_counts().head(3).to_dict()
        stats_text = "\n".join([f"- {user}: {count}ê°œ ë©”ì‹œì§€" for user, count in user_stats.items()])
        
        base_info = f"""
ğŸ“Š **ë¶„ì„ ê°œìš”:**
- ë¶„ì„ ëŒ€ìƒ: {target_user}
- ì´ ë©”ì‹œì§€ ìˆ˜: {len(data):,}ê°œ
- ì°¸ì—¬ì ìˆ˜: {data['user'].nunique()}ëª…
- ë¶„ì„ ê¸°ê°„: {data['datetime'].min().strftime('%Y-%m-%d')} ~ {data['datetime'].max().strftime('%Y-%m-%d')}

ğŸ‘¥ **ì£¼ìš” ì°¸ì—¬ì:**
{stats_text}

ğŸ’¬ **ì±„íŒ… ë‚´ìš©:**
{messages_text}
"""
        
        if analysis_type == "ì¢…í•© ë¶„ì„" or analysis_type == "ì „ì²´ ë¶„ì„":
            return f"""
ë‹¤ìŒ ì¹´ì¹´ì˜¤í†¡ ì±„íŒ… ë‚´ìš©ì„ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”:

{base_info}

ë¶„ì„í•´ì£¼ì„¸ìš”:
1. ì£¼ìš” ëŒ€í™” ì£¼ì œë“¤
2. ì°¸ì—¬ìë“¤ì˜ ëŒ€í™” íŒ¨í„´
3. ì¤‘ìš”í•œ í‚¤ì›Œë“œë‚˜ ì´ìŠˆ
4. ì „ë°˜ì ì¸ ë¶„ìœ„ê¸°ë‚˜ í†¤
5. ì£¼ëª©í• ë§Œí•œ ì¸ì‚¬ì´íŠ¸

í•œêµ­ì–´ë¡œ ìƒì„¸í•˜ê²Œ ë¶„ì„ ê²°ê³¼ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”.
"""
        
        elif analysis_type == "ê°ì • ë¶„ì„":
            return f"""
ë‹¤ìŒ ì¹´ì¹´ì˜¤í†¡ ì±„íŒ…ì˜ ê°ì •ì„ ë¶„ì„í•´ì£¼ì„¸ìš”:

{base_info}

ë¶„ì„í•´ì£¼ì„¸ìš”:
1. ì „ì²´ì ì¸ ê°ì • í†¤ (ê¸ì •/ë¶€ì •/ì¤‘ë¦½ì˜ ë¹„ìœ¨)
2. ì‹œê°„ëŒ€ë³„ ê°ì • ë³€í™”
3. ì£¼ìš” ê°ì • í‘œí˜„ë“¤
4. ê°ì •ì´ ê¸‰ë³€í•œ ì§€ì ê³¼ ì›ì¸
5. ì°¸ì—¬ìë³„ ê°ì • íŠ¹ì„±

ê²°ê³¼ë¥¼ êµ¬ì²´ì ì¸ ì˜ˆì‹œì™€ í•¨ê»˜ í•œêµ­ì–´ë¡œ ì œê³µí•´ì£¼ì„¸ìš”.
"""
        
        elif analysis_type == "ì£¼ìš” ì£¼ì œ ë¶„ì„" or analysis_type == "í† í”½ ë¶„ì„":
            return f"""
ë‹¤ìŒ ì¹´ì¹´ì˜¤í†¡ ì±„íŒ…ì˜ ì£¼ìš” ì£¼ì œë“¤ì„ ë¶„ì„í•´ì£¼ì„¸ìš”:

{base_info}

ë¶„ì„í•´ì£¼ì„¸ìš”:
1. ì£¼ìš” ëŒ€í™” í† í”½ë“¤ (3-5ê°œ)
2. ê° í† í”½ë³„ ë¹„ì¤‘ê³¼ ì¤‘ìš”ë„
3. í† í”½ ê°„ì˜ ì—°ê´€ì„±
4. ì‹œê°„ì˜ íë¦„ì— ë”°ë¥¸ í† í”½ ë³€í™”
5. ì°¸ì—¬ìë³„ ê´€ì‹¬ í† í”½

ê° í† í”½ì„ êµ¬ì²´ì ì¸ ì˜ˆì‹œì™€ í•¨ê»˜ í•œêµ­ì–´ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”.
"""
        
        elif analysis_type == "ì‚¬ìš©ì íŠ¹ì„± ë¶„ì„":
            return f"""
ë‹¤ìŒ ì¹´ì¹´ì˜¤í†¡ ì±„íŒ…ì—ì„œ ì‚¬ìš©ìë“¤ì˜ íŠ¹ì„±ì„ ë¶„ì„í•´ì£¼ì„¸ìš”:

{base_info}

ë¶„ì„í•´ì£¼ì„¸ìš”:
1. ì£¼ìš” ì°¸ì—¬ìë“¤ì˜ ëŒ€í™” ìŠ¤íƒ€ì¼
2. ê° ì‚¬ìš©ìë³„ ê´€ì‹¬ì‚¬ì™€ í™”ì œ
3. ë©”ì‹œì§€ íŒ¨í„´ê³¼ í™œë™ì„±
4. ì‚¬ìš©ì ê°„ì˜ ìƒí˜¸ì‘ìš© íŠ¹ì„±
5. ê°œì„±ì ì¸ ì–¸ì–´ ì‚¬ìš© íŒ¨í„´

ê° ì‚¬ìš©ìì˜ íŠ¹ì§•ì„ êµ¬ì²´ì ìœ¼ë¡œ í•œêµ­ì–´ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”.
"""
        
        elif analysis_type == "ì£¼ìš” í‚¤ì›Œë“œ ì¶”ì¶œ":
            return f"""
ë‹¤ìŒ ì¹´ì¹´ì˜¤í†¡ ì±„íŒ…ì—ì„œ ì£¼ìš” í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”:

{base_info}

ì¶”ì¶œí•´ì£¼ì„¸ìš”:
1. ê°€ì¥ ìì£¼ ì–¸ê¸‰ëœ í‚¤ì›Œë“œ TOP 10
2. ì¸ë¬¼/ê¸°ì—…/ì œí’ˆëª…
3. ì£¼ì‹/íˆ¬ì ê´€ë ¨ í‚¤ì›Œë“œ (ìˆë‹¤ë©´)
4. íŠ¸ë Œë“œ/ì´ìŠˆ í‚¤ì›Œë“œ
5. ê°ì • í‚¤ì›Œë“œ

ê° í‚¤ì›Œë“œì˜ ì–¸ê¸‰ ë¹ˆë„ì™€ ë¬¸ë§¥ì„ í¬í•¨í•´ì„œ í•œêµ­ì–´ë¡œ ì •ë¦¬í•´ì£¼ì„¸ìš”.
"""
        
        elif analysis_type == "ìš”ì•½":
            return f"""
ë‹¤ìŒ ì¹´ì¹´ì˜¤í†¡ ì±„íŒ…ì„ ìš”ì•½í•´ì£¼ì„¸ìš”:

{base_info}

ìš”ì•½í•´ì£¼ì„¸ìš”:
1. í•µì‹¬ ë‚´ìš© 3-5ì¤„ ìš”ì•½
2. ì£¼ìš” ê²°ì •ì‚¬í•­ì´ë‚˜ í•©ì˜ì 
3. ì¤‘ìš”í•œ ì •ë³´ë‚˜ ê³µì§€ì‚¬í•­
4. í›„ì† ì¡°ì¹˜ê°€ í•„ìš”í•œ ë‚´ìš©
5. ë†“ì¹˜ë©´ ì•ˆ ë˜ëŠ” ì¤‘ìš” í¬ì¸íŠ¸

ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ í•œêµ­ì–´ë¡œ ìš”ì•½í•´ì£¼ì„¸ìš”.
"""
        
        else:
            # ê¸°ë³¸ ë¶„ì„ (ì˜ˆìƒì¹˜ ëª»í•œ ë¶„ì„ íƒ€ì…ì˜ ê²½ìš°)
            return f"""
ë‹¤ìŒ ì¹´ì¹´ì˜¤í†¡ ì±„íŒ…ì„ "{analysis_type}" ê´€ì ì—ì„œ ë¶„ì„í•´ì£¼ì„¸ìš”:

{base_info}

ìš”ì²­í•˜ì‹  "{analysis_type}" ë¶„ì„ì„ ìˆ˜í–‰í•˜ê³ , ê´€ë ¨ëœ ì¸ì‚¬ì´íŠ¸ì™€ íŒ¨í„´ì„ ì°¾ì•„ì„œ í•œêµ­ì–´ë¡œ ìì„¸íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”.
"""
    
    def structure_results(self, analysis_result, analysis_type):
        """ë¶„ì„ ê²°ê³¼ë¥¼ êµ¬ì¡°í™”"""
        
        # í‚¤ì›Œë“œ ì¶”ì¶œ ì‹œë„
        keywords = self.extract_keywords_from_text(analysis_result)
        
        result = {
            "summary": analysis_result,
            "analysis_type": analysis_type,
            "timestamp": datetime.now().isoformat(),
            "keywords": keywords
        }
        
        return result
    
    def extract_keywords_from_text(self, text):
        """í…ìŠ¤íŠ¸ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ì¶”ì¶œ (ê°œì„  ê°€ëŠ¥)
        keywords = []
        
        # ë²ˆí˜¸ ë¦¬ìŠ¤íŠ¸ íŒ¨í„´ (1., 2., - ë“±)
        patterns = [
            r'\d+\.\s*([^\n]+)',
            r'[-â€¢]\s*([^\n]+)',
            r'TOP\s*\d+[:\s]*([^\n]+)'
        ]
        
        for pattern in patterns:
            matches = re.findall(pattern, text)
            keywords.extend([match.strip() for match in matches])
        
        return keywords[:10]  # ìƒìœ„ 10ê°œë§Œ ë°˜í™˜
    
    def analyze_sentiment_batch(self, messages):
        """ë©”ì‹œì§€ ì¼ê´„ ê°ì • ë¶„ì„"""
        
        # ë©”ì‹œì§€ë¥¼ ì ì ˆí•œ í¬ê¸°ë¡œ ë¬¶ì–´ì„œ ë¶„ì„
        batch_size = 20
        results = []
        
        for i in range(0, len(messages), batch_size):
            batch = messages[i:i+batch_size]
            batch_text = "\n".join([f"{idx}: {msg}" for idx, msg in enumerate(batch)])
            
            prompt = f"""
ë‹¤ìŒ ë©”ì‹œì§€ë“¤ì˜ ê°ì •ì„ ë¶„ì„í•´ì„œ ê°ê°ì— ëŒ€í•´ 'ê¸ì •', 'ë¶€ì •', 'ì¤‘ë¦½' ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•´ì£¼ì„¸ìš”:

{batch_text}

ê²°ê³¼ë¥¼ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì œê³µí•´ì£¼ì„¸ìš”:
0: ê¸ì •
1: ì¤‘ë¦½
2: ë¶€ì •
...
"""
            
            try:
                response = self.client.chat.completions.create(
                    model=self.model,
                    messages=[
                        {"role": "system", "content": "ë‹¹ì‹ ì€ í…ìŠ¤íŠ¸ ê°ì • ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                        {"role": "user", "content": prompt}
                    ],
                    max_tokens=500,
                    temperature=0.3
                )
                
                batch_results = self.parse_sentiment_results(response.choices[0].message.content)
                results.extend(batch_results)
                
            except:
                # ì˜¤ë¥˜ ì‹œ ì¤‘ë¦½ìœ¼ë¡œ ì²˜ë¦¬
                results.extend(['ì¤‘ë¦½'] * len(batch))
        
        return results
    
    def parse_sentiment_results(self, text):
        """ê°ì • ë¶„ì„ ê²°ê³¼ íŒŒì‹±"""
        sentiments = []
        lines = text.strip().split('\n')
        
        for line in lines:
            if ':' in line:
                sentiment = line.split(':')[1].strip()
                if sentiment in ['ê¸ì •', 'ë¶€ì •', 'ì¤‘ë¦½']:
                    sentiments.append(sentiment)
        
        return sentiments 
    
    def analyze_chat_with_custom_prompt(self, data, custom_prompt, target_user="ì „ì²´", detailed=False, include_context=True):
        """ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸ë¡œ ì±„íŒ… ë°ì´í„° ë¶„ì„"""
        
        # ë°ì´í„° ì „ì²˜ë¦¬
        if target_user != "ì „ì²´" and target_user != "ë¹„êµ ë¶„ì„":
            data = data[data['user'] == target_user]
        
        # ë©”ì‹œì§€ê°€ ë„ˆë¬´ ë§ìœ¼ë©´ ìƒ˜í”Œë§
        if len(data) > 1000:
            if detailed:
                # ìƒì„¸ ë¶„ì„ ì‹œì—ëŠ” ë” ë§ì€ ë°ì´í„° ì‚¬ìš©
                data = data.tail(800)
            else:
                data = data.tail(500)
        
        # í”„ë¡¬í”„íŠ¸ ìƒì„±
        full_prompt = self.generate_custom_prompt(data, custom_prompt, include_context, detailed)
        
        try:
            # í† í° ìˆ˜ì— ë”°ë¼ ëª¨ë¸ ì„ íƒ
            max_tokens = 3000 if detailed else 2000
            
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ì¹´ì¹´ì˜¤í†¡ ì±„íŒ… ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ì±„íŒ… ë°ì´í„°ë¥¼ ì •í™•í•˜ê³  í†µì°°ë ¥ ìˆê²Œ ë¶„ì„í•˜ì—¬ ìœ ìš©í•œ ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”. í•œêµ­ì–´ë¡œ ìì„¸í•˜ê³  êµ¬ì²´ì ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”."},
                    {"role": "user", "content": full_prompt}
                ],
                max_tokens=max_tokens,
                temperature=0.7
            )
            
            analysis_result = response.choices[0].message.content
            
            # ê²°ê³¼ êµ¬ì¡°í™” (í–¥ìƒëœ ë²„ì „)
            return self.structure_advanced_results(analysis_result, custom_prompt, data)
            
        except Exception as e:
            return {
                "summary": f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
                "error": True,
                "analysis_mode": "ì»¤ìŠ¤í…€ ë¶„ì„"
            }
    
    def generate_custom_prompt(self, data, custom_prompt, include_context=True, detailed=False):
        """ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        
        # ë°ì´í„° ìš”ì•½ ì •ë³´
        total_messages = len(data)
        unique_users = data['user'].nunique()
        date_range = f"{data['datetime'].min().strftime('%Y-%m-%d')} ~ {data['datetime'].max().strftime('%Y-%m-%d')}"
        
        # ì‚¬ìš©ìë³„ ë©”ì‹œì§€ ìˆ˜ í†µê³„
        user_stats = data['user'].value_counts().head(5).to_dict()
        stats_text = "\n".join([f"- {user}: {count}ê°œ ë©”ì‹œì§€" for user, count in user_stats.items()])
        
        # ë©”ì‹œì§€ í…ìŠ¤íŠ¸ ì¤€ë¹„
        if include_context:
            # ì‹œê°„ ìˆœì„œì™€ ëŒ€í™” ë§¥ë½ í¬í•¨
            messages_text = "\n".join([
                f"[{row['datetime'].strftime('%m-%d %H:%M')}] {row['user']}: {row['message']}"
                for _, row in data.iterrows()
            ])
        else:
            # ë‹¨ìˆœ ë©”ì‹œì§€ë§Œ
            messages_text = "\n".join([
                f"{row['user']}: {row['message']}"
                for _, row in data.iterrows()
            ])
        
        # í† í° ì œí•œ (detailed ëª¨ë“œì— ë”°ë¼ ì¡°ì •)
        max_chars = 6000 if detailed else 4000
        if len(messages_text) > max_chars:
            messages_text = messages_text[:max_chars] + "\n... (ë©”ì‹œì§€ê°€ ë” ìˆìŠµë‹ˆë‹¤)"
        
        base_info = f"""
ğŸ“Š **ë°ì´í„° ê°œìš”:**
- ì´ ë©”ì‹œì§€ ìˆ˜: {total_messages:,}ê°œ
- ì°¸ì—¬ì ìˆ˜: {unique_users}ëª…
- ë¶„ì„ ê¸°ê°„: {date_range}

ğŸ‘¥ **ì£¼ìš” ì°¸ì—¬ìë³„ ë©”ì‹œì§€ ìˆ˜:**
{stats_text}

ğŸ’¬ **ì±„íŒ… ë‚´ìš©:**
{messages_text}
"""
        
        full_prompt = f"""
{custom_prompt}

{base_info}

ìœ„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìš”ì²­ëœ ë¶„ì„ì„ ìˆ˜í–‰í•´ì£¼ì„¸ìš”. êµ¬ì²´ì ì¸ ì˜ˆì‹œì™€ ë°ì´í„°ë¥¼ ì¸ìš©í•˜ë©° ë¶„ì„í•´ì£¼ì„¸ìš”.
"""
        
        return full_prompt
    
    def structure_advanced_results(self, analysis_result, custom_prompt, data):
        """í–¥ìƒëœ ë¶„ì„ ê²°ê³¼ êµ¬ì¡°í™”"""
        
        # í‚¤ì›Œë“œ ì¶”ì¶œ (í–¥ìƒëœ ë²„ì „)
        keywords = self.extract_advanced_keywords(analysis_result)
        
        # ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ
        insights = self.extract_insights(analysis_result)
        
        # ê¶Œì¥ì‚¬í•­ ì¶”ì¶œ
        recommendations = self.extract_recommendations(analysis_result)
        
        result = {
            "summary": analysis_result,
            "custom_prompt": custom_prompt[:100] + "..." if len(custom_prompt) > 100 else custom_prompt,
            "timestamp": datetime.now().isoformat(),
            "keywords": keywords,
            "insights": insights,
            "recommendations": recommendations,
            "data_stats": {
                "total_messages": len(data),
                "unique_users": data['user'].nunique(),
                "date_range": f"{data['datetime'].min().strftime('%Y-%m-%d')} ~ {data['datetime'].max().strftime('%Y-%m-%d')}"
            }
        }
        
        return result
    
    def extract_advanced_keywords(self, text):
        """í–¥ìƒëœ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        keywords = []
        
        # ë‹¤ì–‘í•œ íŒ¨í„´ìœ¼ë¡œ í‚¤ì›Œë“œ ì¶”ì¶œ
        patterns = [
            r'ì£¼ìš” í‚¤ì›Œë“œ[:\s]*([^\n]+)',
            r'í•µì‹¬ í‚¤ì›Œë“œ[:\s]*([^\n]+)',
            r'í‚¤ì›Œë“œ[:\s]*([^\n]+)',
            r'\*\*([^*]+)\*\*',  # **í‚¤ì›Œë“œ** í˜•íƒœ
            r'ã€Œ([^ã€]+)ã€',      # ã€Œí‚¤ì›Œë“œã€ í˜•íƒœ
            r'\'([^\']+)\'',     # 'í‚¤ì›Œë“œ' í˜•íƒœ
            r'\"([^\"]+)\"',     # "í‚¤ì›Œë“œ" í˜•íƒœ
            r'\d+\.\s*([^\n:]+)[:\n]',  # ë²ˆí˜¸ ë¦¬ìŠ¤íŠ¸
            r'[-â€¢]\s*([^\n:]+)[:\n]',   # ë¶ˆë¦¿ í¬ì¸íŠ¸
        ]
        
        for pattern in patterns:
            matches = re.findall(pattern, text, re.IGNORECASE)
            for match in matches:
                clean_keyword = match.strip().replace(':', '').replace('\n', ' ')
                if 2 <= len(clean_keyword) <= 50:  # ì ì ˆí•œ ê¸¸ì´ì˜ í‚¤ì›Œë“œë§Œ
                    keywords.append(clean_keyword)
        
        # ì¤‘ë³µ ì œê±° ë° ìƒìœ„ í‚¤ì›Œë“œ ë°˜í™˜
        unique_keywords = list(dict.fromkeys(keywords))
        return unique_keywords[:15]
    
    def extract_insights(self, text):
        """ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ"""
        insights = []
        
        # ì¸ì‚¬ì´íŠ¸ë¥¼ ë‚˜íƒ€ë‚´ëŠ” íŒ¨í„´ë“¤
        insight_patterns = [
            r'ì¸ì‚¬ì´íŠ¸[:\s]*([^\n]+)',
            r'í†µì°°[:\s]*([^\n]+)',
            r'ì£¼ëª©í• [^:]*[:\s]*([^\n]+)',
            r'í¥ë¯¸ë¡œìš´[^:]*[:\s]*([^\n]+)',
            r'íŠ¹ì§•ì ì¸[^:]*[:\s]*([^\n]+)',
            r'ëˆˆì— ë„ëŠ”[^:]*[:\s]*([^\n]+)',
            r'ì¤‘ìš”í•œ ì [:\s]*([^\n]+)',
            r'í•µì‹¬[^:]*[:\s]*([^\n]+)'
        ]
        
        for pattern in insight_patterns:
            matches = re.findall(pattern, text, re.IGNORECASE)
            for match in matches:
                clean_insight = match.strip()
                if 10 <= len(clean_insight) <= 200:
                    insights.append(clean_insight)
        
        return insights[:8]
    
    def extract_recommendations(self, text):
        """ê¶Œì¥ì‚¬í•­ ì¶”ì¶œ"""
        recommendations = []
        
        # ê¶Œì¥ì‚¬í•­ì„ ë‚˜íƒ€ë‚´ëŠ” íŒ¨í„´ë“¤
        recommendation_patterns = [
            r'ê¶Œì¥[^:]*[:\s]*([^\n]+)',
            r'ì œì•ˆ[^:]*[:\s]*([^\n]+)',
            r'ê°œì„ [^:]*[:\s]*([^\n]+)',
            r'í–¥í›„[^:]*[:\s]*([^\n]+)',
            r'ì•ìœ¼ë¡œ[^:]*[:\s]*([^\n]+)',
            r'ê³ ë ¤ì‚¬í•­[:\s]*([^\n]+)',
            r'ì£¼ì˜[^:]*[:\s]*([^\n]+)'
        ]
        
        for pattern in recommendation_patterns:
            matches = re.findall(pattern, text, re.IGNORECASE)
            for match in matches:
                clean_rec = match.strip()
                if 10 <= len(clean_rec) <= 200:
                    recommendations.append(clean_rec)
        
        return recommendations[:5]
    
    def analyze_topic(self, data, topic, analysis_type="í† í”½ ë¶„ì„"):
        """íŠ¹ì • ì£¼ì œ ë¶„ì„"""
        # ì£¼ì œ ê´€ë ¨ ë©”ì‹œì§€ í•„í„°ë§
        topic_data = data[data['message'].str.contains(topic, case=False, na=False)]
        
        if len(topic_data) == 0:
            return {
                "summary": f"'{topic}' ê´€ë ¨ ë©”ì‹œì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                "keywords": [],
                "insights": [],
                "analysis_type": f"{topic} ë¶„ì„"
            }
        
        prompt = f"""
ë‹¤ìŒì€ '{topic}' ì£¼ì œì™€ ê´€ë ¨ëœ ì¹´ì¹´ì˜¤í†¡ ì±„íŒ… ë©”ì‹œì§€ë“¤ì…ë‹ˆë‹¤:

ì´ {len(topic_data)}ê°œì˜ ê´€ë ¨ ë©”ì‹œì§€ (ì „ì²´ {len(data)}ê°œ ì¤‘)
ê¸°ê°„: {topic_data['datetime'].min().strftime('%Y-%m-%d')} ~ {topic_data['datetime'].max().strftime('%Y-%m-%d')}

ê´€ë ¨ ë©”ì‹œì§€ë“¤:
{chr(10).join([f"[{row['datetime'].strftime('%m-%d %H:%M')}] {row['user']}: {row['message']}" for _, row in topic_data.head(100).iterrows()])}

'{topic}' ì£¼ì œì— ëŒ€í•´ ë‹¤ìŒì„ ë¶„ì„í•´ì£¼ì„¸ìš”:
1. ì£¼ì œì— ëŒ€í•œ ì „ë°˜ì ì¸ ì˜ê²¬ê³¼ ë¶„ìœ„ê¸°
2. ì£¼ìš” ë…¼ì ë“¤ê³¼ ìŸì 
3. ì°¸ì—¬ìë“¤ì˜ ê´€ì‹¬ë„ì™€ ë°˜ì‘
4. ê´€ë ¨ í‚¤ì›Œë“œì™€ ì–¸ê¸‰ ë¹ˆë„
5. ì‹œê°„ì˜ íë¦„ì— ë”°ë¥¸ ë³€í™”

í•œêµ­ì–´ë¡œ êµ¬ì²´ì ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”.
"""
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ì£¼ì œë³„ ì±„íŒ… ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. íŠ¹ì • ì£¼ì œì— ëŒ€í•œ ëŒ€í™” ë‚´ìš©ì„ ì‹¬ì¸µ ë¶„ì„í•´ì£¼ì„¸ìš”."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=2500,
                temperature=0.7
            )
            
            analysis_result = response.choices[0].message.content
            return self.structure_advanced_results(analysis_result, f"{topic} ë¶„ì„", topic_data)
            
        except Exception as e:
            return {
                "summary": f"'{topic}' ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
                "error": True,
                "analysis_type": f"{topic} ë¶„ì„"
            }
    
    def analyze_user(self, data, user, analysis_type="ì‚¬ìš©ì ë¶„ì„"):
        """íŠ¹ì • ì‚¬ìš©ì ë¶„ì„"""
        user_data = data[data['user'] == user]
        
        if len(user_data) == 0:
            return {
                "summary": f"'{user}' ì‚¬ìš©ìì˜ ë©”ì‹œì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                "keywords": [],
                "insights": [],
                "analysis_type": f"{user} ë¶„ì„"
            }
        
        # ì‚¬ìš©ì í†µê³„
        total_messages = len(user_data)
        time_range = f"{user_data['datetime'].min().strftime('%Y-%m-%d')} ~ {user_data['datetime'].max().strftime('%Y-%m-%d')}"
        avg_length = user_data['message'].str.len().mean()
        
        prompt = f"""
'{user}' ì‚¬ìš©ìì˜ ì±„íŒ… íŒ¨í„´ì„ ë¶„ì„í•´ì£¼ì„¸ìš”:

ğŸ“Š ê¸°ë³¸ í†µê³„:
- ì´ ë©”ì‹œì§€ ìˆ˜: {total_messages}ê°œ
- í™œë™ ê¸°ê°„: {time_range}
- í‰ê·  ë©”ì‹œì§€ ê¸¸ì´: {avg_length:.1f}ì

ìµœê·¼ ë©”ì‹œì§€ë“¤:
{chr(10).join([f"[{row['datetime'].strftime('%m-%d %H:%M')}] {row['message']}" for _, row in user_data.tail(50).iterrows()])}

ë‹¤ìŒì„ ë¶„ì„í•´ì£¼ì„¸ìš”:
1. ì£¼ìš” ê´€ì‹¬ì‚¬ì™€ í™”ì œ
2. ë©”ì‹œì§€ ìŠ¤íƒ€ì¼ê³¼ íŠ¹ì§•
3. í™œë™ íŒ¨í„´ (ì‹œê°„ëŒ€, ë¹ˆë„ ë“±)
4. ìì£¼ ì‚¬ìš©í•˜ëŠ” í‚¤ì›Œë“œ
5. ëŒ€í™” ì°¸ì—¬ ìŠ¤íƒ€ì¼ê³¼ ì„±í–¥

í•œêµ­ì–´ë¡œ êµ¬ì²´ì ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”.
"""
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ì‚¬ìš©ì í–‰ë™ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ê°œì¸ì˜ ì±„íŒ… íŒ¨í„´ê³¼ íŠ¹ì„±ì„ ë¶„ì„í•´ì£¼ì„¸ìš”."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=2500,
                temperature=0.7
            )
            
            analysis_result = response.choices[0].message.content
            return self.structure_advanced_results(analysis_result, f"{user} ë¶„ì„", user_data)
            
        except Exception as e:
            return {
                "summary": f"'{user}' ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
                "error": True,
                "analysis_type": f"{user} ë¶„ì„"
            }
    
    def compare_users(self, data, users, analysis_type="ë¹„êµ ë¶„ì„"):
        """ì—¬ëŸ¬ ì‚¬ìš©ì ë¹„êµ ë¶„ì„"""
        if len(users) < 2:
            return {
                "summary": "ë¹„êµ ë¶„ì„ì„ ìœ„í•´ì„œëŠ” ìµœì†Œ 2ëª…ì˜ ì‚¬ìš©ìê°€ í•„ìš”í•©ë‹ˆë‹¤.",
                "keywords": [],
                "insights": [],
                "analysis_type": "ë¹„êµ ë¶„ì„"
            }
        
        # ê° ì‚¬ìš©ìë³„ ë°ì´í„° ìˆ˜ì§‘
        user_stats = {}
        user_messages = {}
        
        for user in users:
            user_data = data[data['user'] == user]
            if len(user_data) > 0:
                user_stats[user] = {
                    "message_count": len(user_data),
                    "avg_length": user_data['message'].str.len().mean(),
                    "date_range": f"{user_data['datetime'].min().strftime('%m-%d')} ~ {user_data['datetime'].max().strftime('%m-%d')}"
                }
                user_messages[user] = user_data.tail(20)  # ìµœê·¼ 20ê°œ ë©”ì‹œì§€
        
        # í†µê³„ í…ìŠ¤íŠ¸ ìƒì„±
        stats_text = "\n".join([
            f"**{user}**: {stats['message_count']}ê°œ ë©”ì‹œì§€, í‰ê·  {stats['avg_length']:.1f}ì, í™œë™ê¸°ê°„: {stats['date_range']}"
            for user, stats in user_stats.items()
        ])
        
        # ë©”ì‹œì§€ ìƒ˜í”Œ ìƒì„±
        messages_text = ""
        for user, messages in user_messages.items():
            messages_text += f"\n### {user}ì˜ ìµœê·¼ ë©”ì‹œì§€:\n"
            messages_text += "\n".join([f"- {row['message']}" for _, row in messages.iterrows()])
            messages_text += "\n"
        
        prompt = f"""
ë‹¤ìŒ ì‚¬ìš©ìë“¤ì„ ë¹„êµ ë¶„ì„í•´ì£¼ì„¸ìš”: {', '.join(users)}

ğŸ“Š ê¸°ë³¸ í†µê³„:
{stats_text}

ğŸ“ ë©”ì‹œì§€ ìƒ˜í”Œ:
{messages_text}

ë‹¤ìŒì„ ë¹„êµ ë¶„ì„í•´ì£¼ì„¸ìš”:
1. ê° ì‚¬ìš©ìì˜ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ìŠ¤íƒ€ì¼
2. ê´€ì‹¬ì‚¬ì™€ ì£¼ì œ ì„ í˜¸ë„ ì°¨ì´
3. ë©”ì‹œì§€ íŒ¨í„´ê³¼ í™œë™ì„±
4. ì–¸ì–´ ì‚¬ìš© íŠ¹ì§• (ì´ëª¨í‹°ì½˜, ì¤„ì„ë§ ë“±)
5. ëŒ€í™” ì°¸ì—¬ ë°©ì‹ì˜ ì°¨ì´ì 

ê° ì‚¬ìš©ìì˜ íŠ¹ì§•ì„ êµ¬ì²´ì ìœ¼ë¡œ ë¹„êµí•´ì„œ í•œêµ­ì–´ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”.
"""
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ì‚¬ìš©ì ë¹„êµ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì—¬ëŸ¬ ì‚¬ìš©ìì˜ ì±„íŒ… íŒ¨í„´ì„ ë¹„êµí•˜ì—¬ ê°ìì˜ íŠ¹ì§•ê³¼ ì°¨ì´ì ì„ ë¶„ì„í•´ì£¼ì„¸ìš”."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=3000,
                temperature=0.7
            )
            
            analysis_result = response.choices[0].message.content
            
            # ë¹„êµ ë¶„ì„ìš© ë°ì´í„° ê²°í•©
            compare_data = pd.concat([data[data['user'] == user] for user in users if user in data['user'].values])
            
            return self.structure_advanced_results(analysis_result, f"{', '.join(users)} ë¹„êµ ë¶„ì„", compare_data)
            
        except Exception as e:
            return {
                "summary": f"ì‚¬ìš©ì ë¹„êµ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
                "error": True,
                "analysis_type": "ë¹„êµ ë¶„ì„"
            }
    
    def custom_analysis(self, data, custom_prompt):
        """ì»¤ìŠ¤í…€ ë¶„ì„"""
        return self.analyze_chat_with_custom_prompt(data, custom_prompt)